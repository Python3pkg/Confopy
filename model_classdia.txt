# Confopy class diagram
# Using Hafer:
# https://github.com/ooz/Hafer

model:
######

[DocumentConverter
|+to_Documents(xml_paths : list<unicode>) : list<Document>
;+to_XML(doc : Document, pretty : bool, linesep : unicode, ident : unicode, header : bool)
]

model.document:
###############

[Node
|+text : unicode
;+pagenr : unicode
;-parent   : Node
;-children : list<Node>
|+parent() : Node
;+children() : list<Node>
;+is_root() : bool
;+is_leaf() : bool
;+is_section() : bool
;+is_paragraph() : bool
;+is_float() : bool
;+is_footnote() : bool
;+add_child(child : Node, relation : int)
;+remove_child(child : Node)
;+sections() : list<Node>
;+paragraphs(recursive : bool) : list<Node>
;+floats(recursive : bool) : list<Node>
;+lines(recursive : bool, ignore_floats : bool) : list<unicode>
;+raw(recursive : bool, ignore_floats : bool) : unicode
;+words(recursive : bool, ignore_floats : bool) : list<unicode>
;+sents(recursive : bool, ignore_floats : bool) : list<list<unicode>>
]

[Float
#|DUMMY
#;FIGURE
#;TABLE
#;LISTING
#;DEFINITION
#;FORMULA
#;THEOREM
#;PROOF
#;+caption : unicode
# label / key
|+number : unicode
]
[Node]^--[Float]
[Float]^--[Footnote]

#[Node]^--[Misc]

[Paragraph
|+font : unicode
;+fontsize : unicode
;+emph : list<unicode>
;+word_count : int
]
[Node]^--[Paragraph]

[Section
|+title : unicode
;+number : unicode
]
[Node]^--[Section]

[Chapter]
[Section]^--[Chapter]

[Document
]
[Section]^--[Document]

[Meta
|+title : unicode
;+authors : list<unicode>
;+language : unicode
]
[Document]1---1[Meta]

#[DocumentChecker
#|+cleanup(doc : Document) : Document]



analysis:
#########

[RuleKind
|DOCUMENT
;SECTION
;PARAGRAPH
;FLOAT
]

[Analyzer
|+instance(lang : unicode) : Analyzer
#;+register(metric : Metric, rule : Rule, report : Report)
;+register(obj : object)
;+languages() : list<unicode>
;+get(metric : unicode, rule : unicode, report : unicode, corpus : unicode) : object
#;+get_metric(ID : unicode) : Metric
#;+get_rule  (ID : unicode) : Rule
#;+get_report(ID : unicode) : Report
;+metrics() : dict<unicode, Metric>
;+rules  () : dict<unicode, Rule>  
;+reports() : dict<unicode, Report>
;-languages() : list<unicode>
;+reportlist(lang : unicode) : unicode
;+metriclist(lang : unicode) : unicode
]

[Localizable
|+ID : unicode
;+language : unicode
;+brief : unicode
;+description : unicode
]

[Corpus
|+tagger() : object
;+parser() : object
;+sent_tokenizer() : object
;+fillers() : list<unicode>
]
[Localizable]^--[Corpus]
[model.Document]^--[Corpus]
[nltk.corpus.reader.api.CorpusReader]^--[Corpus]

[Metric
|+evaluate(node : Node) : Float
]
[Metric]--^[Localizable]

[Rule
|+kind : RuleKind
|+evaluate(node : Node) : bool
;+message(node : Node) : unicode
]
[Rule]--^[Localizable]

[Report
|+execute(docs : list<Document>, args : object) : unicode
]
[Report]--^[Localizable]

[SpellChecker
|+check(word : unicode) : bool
;+suggest(word : unicode) : list<unicode>
]



localization.de:
################

[WordLengthMetric]--^[analysis.Metric]
[SpellCheckMetric]--^[analysis.Metric]
[LexiconMetric]--^[analysis.Metric]
[SentLengthMetric]--^[analysis.Metric]
[PersonalStyleMetric]--^[analysis.Metric]
[ImpersonalStyleMetric]--^[analysis.Metric]
[PassiveConstructsMetric]--^[analysis.Metric]
[SimplePresentMetric]--^[analysis.Metric]
[AdverbModifierMetric]--^[analysis.Metric]
[DeadVerbsMetric]--^[analysis.Metric]
[FillerMetric]--^[analysis.Metric]
[ExampleCountMetric]--^[analysis.Metric]
[SentenceLengthVariationMetric]--^[analysis.Metric]

[MultiDocReport]--^[analysis.Report]
[DocumentComparison]--^[analysis.Report]
[DocumentReport]--^[analysis.Report]
[DocumentDetailedReport]--^[analysis.Report]

[IntroductionRule]--^[analysis.Rule]
[SubsectionRule]--^[analysis.Rule]
[FloatReferenceRule]--^[analysis.Rule]
[FloatCaptionRule]--^[analysis.Rule]

[TigerCorpusReader
|+words(recursive : bool, tokenizer : object) : list<unicode>
;+sents(recursive : bool, tokenizer : object) : list<list<unicode>>
;+paras() : list<list<list<unicode>>>
;+tagged_words() : list<tuple<unicode, unicode>>
;+tagged_sents() : list<list<tuple<unicode, unicode>>>
;+tagged_paras() : list<list<list<tuple<unicode, unicode>>>>
;+parsed_sents() : list<nltk.Tree>
;+parsed_paras() : list<list<nltk.Tree>>
;+tagger(include_edgelabels : bool) : Tagger
;+pcfg(include_edgelabels : bool) : Grammar
;+cfg(include_edgelabels : bool) : Grammar
;+parser(include_edgelabels : bool) : Parser
;+viterbi_parser(include_edgelabels : bool) : Parser
;+sent_tokenizer() : Tokenizer
;+fillers() : list<unicode>
]--^[analysis.Corpus]



pdfextract.pdfminer_xml_bindings:
#################################

[pdfminer_xml_bindings
|SVG_HEADER : unicode
;SVG_FOOTER : unicode
;SVG_LEFT_PADDING : int
;SVG_TOP_PADDING : int
|DOM2pages()
;DOM2page()
;DOM2textbox()
;DOM2textgroup()
;DOM2textline()
;str2bbox()
;bbox2svg()
;find_emph(lines, fonts, sizes) : tuple<unicode, unicode, list>
;emph_words(lines, attributes)
;find_primary_font(textboxes, pages)
]

[Box
|+bbox
|+width()
;+height()
;+as_svg() : str
;_print(pad : unicode)
#;+as_textboxes() : list
#;+as_lines() : list
]

[Page
|+ID : unicode
;+textboxes : list<TextBox>
;+textgroups : list<TextGroup>
;+prim_font : tuple<unicode, unicode, int>
;+word_count : int
|+as_svg() : str
#;+as_textboxes() : list<TextBox>
]
[Box]^--[Page]

[TextBox
|+ID : unicode
;+lines : list<unicode>
;+font : tuple<unicode, unicode>
;+emph : list<unicode>
;+word_count : int
;+character_count : int
#|+as_lines() : list<unicode>
]
[Box]^--[TextBox]

[TextGroup
|+children : list<TextGroup>
]
[Box]^--[TextGroup]

[TextBox]0..*<--++[Page]
[Page]++---->0..*[TextGroup]


pdfextract.heuristics:
######################

[HeuristicType
|WORD_COUNT
;CONTENT
;FONT
;POSITION
;GROUPING
;COMPLEX
]

[TextboxType
|NONE
;TITLE
;TOC
;PAGENR
;HEADER
;FOOTER
;HEADING
;PARAGRAPH
;PARAGRAPH_CONT
;FLOATOBJ
;FLOATCAP
;FOOTNOTE
;UNKNOWN
#;TRASH
]

[Heuristic
|box_kinds : dict
;+kind : HeuristicType
|+apply(page_or_box)
]

[Heuristic]--[Box]
[Heuristic]--[Document]

confopy:
########

[main]
[config
|DEFAULT_LANG]
